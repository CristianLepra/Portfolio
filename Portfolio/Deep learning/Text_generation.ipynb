{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8793839-40cd-4edf-80ad-818c7020588f",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utilizando una red LSTM crear un generador de una secuencia de texto basada en la obra `CRIMEN Y CASTIGO` de **FIODOR DOSTOIEVSKI** que cumpla las siguientes características:\n",
    "\n",
    "- Limpiar el texto de posibles caracteres indeseados\n",
    "- Implementar `PlotLossess` Callback para evaluar los resultados\n",
    "- Implementar `EarlyStopping` con los parámetros que consideres\n",
    "- El accuracy del modelo debe ser superior a 70% (Ejecutar en GPU en Colab o Kaggle)\n",
    "- Configurar un valor de `temperatura` acorde \n",
    "- El modelo debe poder generar(predecir) 500 palabras\n",
    "- Salvar el modelo\n",
    "\n",
    "El corpus lo puedes encontrar [Aquí](https://github.com/senpai-academy/DSB-1-2023/blob/main/6.ml_deep_learning/ejercicios/data/Crimen-y-Castigo.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13bdb9-4024-480e-8da4-f08f21396542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_FOLDER = './data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed665cb-7548-4a06-b0af-32e2981f63c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Limpieza y preparación corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9524a-aa20-4860-b257-c67b39d631df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorizar el texto\n",
    "\n",
    "maxlen = #TODO longitud de las secuencias\n",
    "step =  #TODO  cada cuantas letras empezar una secuencia\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0,len(corpus) - maxlen,step):\n",
    "    sentences.append(corpus[i: i + maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f7135-995b-4eb5-ba98-5221edf4490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(list(set(corpus)))\n",
    "char_indices = {char : i for i,char in enumerate(unique_chars) }\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff19048-e540-42d2-9088-7d29bbe04d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vectorizacion (one hot encoding)\n",
    "x = np.zeros((len(sentences), maxlen,len(unique_chars)), dtype=bool) \n",
    "y = np.zeros((len(sentences), len(unique_chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]] = 1\n",
    "    y[i,char_indices[next_chars[i]]] = 1\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf461595-2a82-43b5-925b-7986f1144d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781d632-a5fe-4513-b338-48bfd129eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73319c52-dca7-4c90-8836-d5097aefacfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "%time\n",
    "\n",
    "history = model.fit() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a90bd-d4f4-4f72-9077-09650a1a77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_distribution(predictions, temperature):\n",
    "    predictions = np.array(predictions).astype('float64')\n",
    "    predictions =  #TODO\n",
    "    exp_predictions = #TODO\n",
    "    predictions = exp_predictions / np.sum(exp_predictions) # asegurarse que los valores suman 1 (probabilidad)\n",
    "    probs = np.random.multinomial(1, predictions, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dda13-293d-4b72-a9be-356dd0095e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# generar secuencias arbitrarias de texto\n",
    "predict_length = #TODO\n",
    "temperature = #TODO\n",
    "\n",
    "start_index = random.randint() #TODO\n",
    "input_text = corpus[] #TODO\n",
    "print('Seed: ' + input_text)\n",
    "generated_text = input_text\n",
    "\n",
    "for i in range(predict_length):\n",
    "    sampled = np.zeros((1, maxlen, len(unique_chars)))\n",
    "    for t, char in enumerate(input_text):\n",
    "        sampled[0,t,char_indices[char]] = 1.\n",
    "    \n",
    "    prediction = model.predict(sampled, verbose=0)[0]\n",
    "    next_index = transform_distribution(prediction,temperature)\n",
    "    next_char = unique_chars[next_index]\n",
    "    \n",
    "    #pegar el nuevo texto\n",
    "    input_text += next_char\n",
    "    generated_text += next_char\n",
    "    input_text = input_text[1:]\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137fbe1-50b0-4e6d-b0f8-4731619be108",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/gen.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
