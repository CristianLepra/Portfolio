{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n14AuNe6QyOe"
      },
      "source": [
        "# Ejercicio - CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlcCQByoQyOe"
      },
      "source": [
        "Hoy en día, existen varias CNN previamente entrenadas disponibles para muchas tareas. Modelos como ResNet, VGG16, InceptionV3 y muchos otros, son altamente eficientes en la mayoría de las tareas de visión por computadora que realizamos actualmente en todas las industrias.\n",
        "\n",
        "En este ejercicio, sin embargo, me gustaría explorar el proceso de construcción de una red neuronal convolucional simple pero efectiva desde cero. Para esta tarea, utilizarás Keras para construir una red neuronal que pueda identificar con precisión enfermedades en una planta a través de imágenes.\n",
        "\n",
        "Vas a utilizar el conjunto de datos de reconocimiento de enfermedades de plantas, que contiene `1530` imágenes divididas en conjuntos de entrenamiento, prueba y validación. Las imágenes están etiquetadas como `Saludable` (healty), `Óxido` (rust) y `Polvo` (Powdery) para describir las condiciones de las plantas.\n",
        "\n",
        "Muy brevemente, cada clase significa lo siguiente:\n",
        "\n",
        "• Rust: Son enfermedades de las plantas causadas por hongos Pucciniales, que provocan severas deformidades en la planta.\n",
        "\n",
        "• Powdery: El mildiú polvoroso es causado por el hongo Erysphales y representa una amenaza para la agricultura y la horticultura al reducir el rendimiento de los cultivos.\n",
        "\n",
        "• Healty: Naturalmente, son las plantas que están libres de enfermedades.\n",
        "\n",
        "\n",
        "Puedes obtener el link de descarga [aquí](https://drive.google.com/drive/folders/1e24quFWVPK6hWeIbrTh2y8z2lgpplPcE?usp=drive_link)\n",
        "\n",
        ">NOTE: Se recomienda crear un link dentro de drive (`My Drive`) o descargar los archivos y subirlos a tu drive tal cual la estructura que se muestra en ese link.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "I6wvoJOURzAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e988c7-f602-44b5-dbcd-e282e1ff3bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.12.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:06.921162Z",
          "iopub.status.busy": "2023-10-15T13:21:06.920839Z",
          "iopub.status.idle": "2023-10-15T13:21:14.163028Z",
          "shell.execute_reply": "2023-10-15T13:21:14.162183Z",
          "shell.execute_reply.started": "2023-10-15T13:21:06.92111Z"
        },
        "id": "oy68kg8qQyOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b6a801fc-a0a8-4fcf-f257-07126df9adb2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "# Data Handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Efficient Looping\n",
        "import itertools\n",
        "\n",
        "# Traceback for diagnosis\n",
        "import traceback\n",
        "\n",
        "# Data Visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.subplots as sp\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.io as pio\n",
        "from IPython.display import display\n",
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "# Statistics & Mathematics\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import shapiro, skew, anderson, kstest\n",
        "import math\n",
        "\n",
        "# Feature Selection\n",
        "from sklearn.feature_selection import (\n",
        "    RFECV, SelectKBest, chi2, f_classif, f_regression,\n",
        "    mutual_info_classif, mutual_info_regression\n",
        ")\n",
        "\n",
        "# Machine Learning Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin,ClassifierMixin\n",
        "\n",
        "# Preprocessing data\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, QuantileTransformer, FunctionTransformer\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Model Selection for Cross Validation\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold, KFold,\n",
        "    RepeatedKFold, RepeatedStratifiedKFold,\n",
        "    train_test_split, TimeSeriesSplit\n",
        ")\n",
        "\n",
        "# Machine Learning metrics\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    mean_absolute_error,\n",
        "    cohen_kappa_score,\n",
        "    make_scorer,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# ML regressors\n",
        "from sklearn.linear_model import HuberRegressor,RANSACRegressor, TheilSenRegressor, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
        "from sklearn.ensemble import (\n",
        "    HistGradientBoostingRegressor, StackingRegressor,\n",
        "    AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor,\n",
        "    GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
        "    )\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "# ML classifiers\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "from sklearn.ensemble import (\n",
        "    HistGradientBoostingClassifier, AdaBoostClassifier,\n",
        "    RandomForestClassifier, GradientBoostingClassifier,\n",
        "    StackingClassifier, VotingClassifier,ExtraTreesClassifier\n",
        "    )\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Clustering algorithms\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Fine-tuning\n",
        "import optuna\n",
        "\n",
        "# Randomizer\n",
        "import random\n",
        "\n",
        "# Encoder of categorical variables\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "\n",
        "# OS\n",
        "import os\n",
        "\n",
        "# Image package\n",
        "from PIL import Image\n",
        "\n",
        "# Hiding warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:14.165302Z",
          "iopub.status.busy": "2023-10-15T13:21:14.164962Z",
          "iopub.status.idle": "2023-10-15T13:21:20.947089Z",
          "shell.execute_reply": "2023-10-15T13:21:20.946182Z",
          "shell.execute_reply.started": "2023-10-15T13:21:14.165273Z"
        },
        "id": "JPzWHNvtQyOf"
      },
      "outputs": [],
      "source": [
        "# Importing Keras\n",
        "from keras.models import Sequential                          # Neural network model as a sequence of layers.\n",
        "from keras.layers import Conv2D                              # Convolutional layer\n",
        "from keras.layers import MaxPooling2D                        # Max pooling layer\n",
        "from keras.layers import Flatten                             # Layer used to flatten 2D arrays for fully-connected layers.\n",
        "from keras.layers import Dense                               # This layer adds fully-connected layers to the neural network.\n",
        "from keras.layers import Dropout                             # This serves to prevent overfitting by dropping out a random set of activations.\n",
        "from keras.layers import BatchNormalization                  # This is used to normalize the activations of the neurons.\n",
        "from keras.layers import Activation                          # Layer for activation functions\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint   # Classes used to save weights and stop training when improvements reach a limit\n",
        "from keras.models import load_model                          # This helps us to load trained models\n",
        "from keras.callbacks import CSVLogger\n",
        "# Preprocessing layers\n",
        "from keras.layers import Rescaling                           # This layer rescales pixel values\n",
        "\n",
        "# Importing TensorFlow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:20.949404Z",
          "iopub.status.busy": "2023-10-15T13:21:20.948332Z",
          "iopub.status.idle": "2023-10-15T13:21:20.954094Z",
          "shell.execute_reply": "2023-10-15T13:21:20.953114Z",
          "shell.execute_reply.started": "2023-10-15T13:21:20.949371Z"
        },
        "id": "B1vJdJU_QyOf"
      },
      "outputs": [],
      "source": [
        "# Configuring notebook\n",
        "seed = 123\n",
        "paper_color = '#EEF6FF'\n",
        "bg_color = '#EEF6FF'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:20.956523Z",
          "iopub.status.busy": "2023-10-15T13:21:20.956031Z",
          "iopub.status.idle": "2023-10-15T13:21:20.966831Z",
          "shell.execute_reply": "2023-10-15T13:21:20.96601Z",
          "shell.execute_reply.started": "2023-10-15T13:21:20.956494Z"
        },
        "id": "KKAHAwGSQyOf"
      },
      "outputs": [],
      "source": [
        "def image_resizer(paths):\n",
        "    \"\"\"\n",
        "    This function resizes the input images\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        resized_images = list(executor.map(lambda x: Image.open(x).resize((350,250)), paths))\n",
        "    return resized_images\n",
        "\n",
        "def plot_images_list(images, title, subtitle):\n",
        "    '''\n",
        "    This functions helps to plot a matrix of images in a list\n",
        "    '''\n",
        "    fig = sp.make_subplots(rows=3, cols=3)\n",
        "    images = image_resizer(images)\n",
        "\n",
        "    traces = []\n",
        "    for i in range(min(9, len(images))):\n",
        "        img = go.Image(z=images[i])\n",
        "        traces.append((img, i//3+1, i%3+1))\n",
        "\n",
        "    fig.add_traces([trace[0] for trace in traces],\n",
        "                  rows = [trace[1] for trace in traces],\n",
        "                  cols = [trace[2] for trace in traces])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={'text': f'<b>{title}<br>  <i><sub>{subtitle}</sub></i></b>',\n",
        "               'font': dict(size = 22)},\n",
        "        height=800,\n",
        "        width=800,\n",
        "        margin=dict(t=110, l=80),\n",
        "        plot_bgcolor=bg_color,paper_bgcolor=paper_color\n",
        "        #template=template\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:20.970796Z",
          "iopub.status.busy": "2023-10-15T13:21:20.970501Z",
          "iopub.status.idle": "2023-10-15T13:21:23.401045Z",
          "shell.execute_reply": "2023-10-15T13:21:23.400015Z",
          "shell.execute_reply.started": "2023-10-15T13:21:20.970769Z"
        },
        "id": "QUX-OAcgQyOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fd6348-6ee6-48fe-cced-bc415fd51bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPU Found! Using GPU...\n"
          ]
        }
      ],
      "source": [
        "# Configuring GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "        print('\\nGPU Found! Using GPU...')\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print('Number of replicas:', strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJhh1IZ4QyOf"
      },
      "source": [
        "## Explorando los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVqamZUYQyOf"
      },
      "source": [
        "Antes de construir nuestra red neuronal convolucional, resulta útil realizar un análisis breve pero eficiente de los datos que tenemos a mano. Comencemos cargando los directorios para cada conjunto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "afs-BH36SkYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17d5915-6ce3-495d-dc48-2a5c467e318c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:23.403024Z",
          "iopub.status.busy": "2023-10-15T13:21:23.402388Z",
          "iopub.status.idle": "2023-10-15T13:21:23.413361Z",
          "shell.execute_reply": "2023-10-15T13:21:23.412392Z",
          "shell.execute_reply.started": "2023-10-15T13:21:23.402991Z"
        },
        "id": "iiuQQxGVQyOg"
      },
      "outputs": [],
      "source": [
        "# Loading training, testing, and validation directories\n",
        "base_path = '/content/drive/MyDrive/Colab_Notebooks/06_Deep_learning/5.archivos/Acceso_directo/'\n",
        "\n",
        "train_dir = os.path.join(base_path,'train/') # TODO completar con path\n",
        "test_dir = os.path.join(base_path,'test/') # TODO completar con path\n",
        "val_dir = os.path.join(base_path,'validation/') # TODO completar con path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_0JoMyOQyOg"
      },
      "source": [
        "También podemos contar los archivos dentro de cada subcarpeta para calcular el total de datos que tenemos para entrenamiento y prueba, así como medir el grado de desequilibrio de clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:23.415255Z",
          "iopub.status.busy": "2023-10-15T13:21:23.414671Z",
          "iopub.status.idle": "2023-10-15T13:21:24.087087Z",
          "shell.execute_reply": "2023-10-15T13:21:24.086078Z",
          "shell.execute_reply.started": "2023-10-15T13:21:23.415226Z"
        },
        "id": "x631s96VQyOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d41660-0265-4c43-85f6-d4af39b9e7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "* * * * * Number of files in each folder * * * * *\n",
            "\n",
            "\n",
            "Train/healthy: 460\n",
            "\n",
            "Train/powdery: 430\n",
            "\n",
            "Train/rust: 434\n",
            "\n",
            "  Total: 1324\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Test/healthy: 50\n",
            "\n",
            "Test/powdery: 50\n",
            "\n",
            "Test/rust: 50\n",
            "\n",
            "  Total: 150\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Validation/healthy: 20\n",
            "\n",
            "Validation/powdery: 20\n",
            "\n",
            "Validation/rust: 20\n",
            "\n",
            "  Total: 60\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Giving names to each directory\n",
        "directories = {\n",
        "    train_dir: 'Train',\n",
        "    test_dir: 'Test',\n",
        "    val_dir: 'Validation'\n",
        "    }\n",
        "\n",
        "# Naming subfolders\n",
        "subfolders = ['healthy', 'powdery', 'rust']\n",
        "\n",
        "print('\\n* * * * * Number of files in each folder * * * * *\\n')\n",
        "\n",
        "# Counting the total of pictures inside each subfolder and directory\n",
        "for dir, name in directories.items():\n",
        "    total = 0\n",
        "    for sub in subfolders:\n",
        "        path = os.path.join(dir, sub)\n",
        "        num_files = len([f for f in os.listdir(path) if os.path.join(path, f)])\n",
        "        total += num_files\n",
        "        print(f'\\n{name}/{sub}: {num_files}')\n",
        "    print(f'\\n  Total: {total}')\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei_yBesGQyOg"
      },
      "source": [
        "Tenemos un total de 1324 archivos dentro del directorio Train y no hay grandes desequilibrios entre clases. Una pequeña variación entre ellos está bien y una métrica simple como la Precisión puede ser suficiente para medir el desempeño.\n",
        "\n",
        "Para el conjunto de prueba, tenemos un total de 150 imágenes, mientras que el conjunto de validación consta de 60 imágenes en total. Ambos conjuntos tienen un equilibrio de clases perfecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:24.089253Z",
          "iopub.status.busy": "2023-10-15T13:21:24.088364Z",
          "iopub.status.idle": "2023-10-15T13:21:44.389186Z",
          "shell.execute_reply": "2023-10-15T13:21:44.388281Z",
          "shell.execute_reply.started": "2023-10-15T13:21:24.089219Z"
        },
        "id": "2qpRJefwQyOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48721c2c-52c5-498f-97a9-50f4a091f12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 8 unique image dimensions: {(4032, 3024), (4000, 2672), (4000, 3000), (5184, 3456), (2592, 1728), (3901, 2607), (4608, 3456), (2421, 2279)}\n"
          ]
        }
      ],
      "source": [
        "unique_dimensions = set()\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                unique_dimensions.add(img.size)\n",
        "\n",
        "if len(unique_dimensions) == 1:\n",
        "    print(f\"\\nAll images have the same dimensions: {unique_dimensions.pop()}\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(unique_dimensions)} unique image dimensions: {unique_dimensions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u1K_ThNQyOh"
      },
      "source": [
        "Tenemos 8 dimensiones diferentes en todo el conjunto de datos. En la siguiente celda, comprobaré la distribución de estas dimensiones en los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:44.391393Z",
          "iopub.status.busy": "2023-10-15T13:21:44.390497Z",
          "iopub.status.idle": "2023-10-15T13:21:45.445296Z",
          "shell.execute_reply": "2023-10-15T13:21:45.444379Z",
          "shell.execute_reply.started": "2023-10-15T13:21:44.391361Z"
        },
        "id": "-yR4JXVjQyOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8aec509-0fd7-4a96-f12e-8af048bd2ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension (4000, 2672): 1132 images\n",
            "\n",
            "Dimension (4000, 3000): 88 images\n",
            "\n",
            "Dimension (2421, 2279): 1 images\n",
            "\n",
            "Dimension (2592, 1728): 127 images\n",
            "\n",
            "Dimension (5184, 3456): 97 images\n",
            "\n",
            "Dimension (4608, 3456): 72 images\n",
            "\n",
            "Dimension (4032, 3024): 16 images\n",
            "\n",
            "Dimension (3901, 2607): 1 images\n"
          ]
        }
      ],
      "source": [
        "# Checking if all the images in the dataset have the same dimensions\n",
        "dims_counts = defaultdict(int)\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                dims_counts[img.size] += 1\n",
        "\n",
        "for dimension, count in dims_counts.items():\n",
        "    print(f\"\\nDimension {dimension}: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucfoEYa-QyOi"
      },
      "source": [
        "Parece que la mayoría de las imágenes tienen dimensiones de 4000x2672, que es una forma rectangular. Podemos concluir que, debido a las diferencias en las dimensiones, necesitaremos aplicar algún preprocesamiento a los datos.\n",
        "\n",
        "Primero, vamos a cambiar el tamaño de las imágenes para que todas tengan la misma forma. Luego, transformaremos la entrada de forma rectangular a forma cuadrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:21:45.446954Z",
          "iopub.status.busy": "2023-10-15T13:21:45.446641Z",
          "iopub.status.idle": "2023-10-15T13:24:08.99774Z",
          "shell.execute_reply": "2023-10-15T13:24:08.996841Z",
          "shell.execute_reply.started": "2023-10-15T13:21:45.446924Z"
        },
        "id": "0JuzHjyyQyOi"
      },
      "outputs": [],
      "source": [
        "# Checking images dtype\n",
        "all_uint8 = True\n",
        "all_in_range = True\n",
        "\n",
        "for dir, name in directories.items():\n",
        "    for sub in subfolders:\n",
        "        folder_path = os.path.join(dir, sub)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                img_array = np.array(img)\n",
        "\n",
        "            if img_array.dtype == 'uint8':\n",
        "                all_uint8 = False\n",
        "\n",
        "            if img_array.min() < 0 or img_array.max() > 255:\n",
        "                all_in_range = False\n",
        "\n",
        "if all_uint8:\n",
        "    print(\" - All images are of data type uint8\\n\")\n",
        "else:\n",
        "    print(\" - Not all images are of data type uint8\\n\")\n",
        "\n",
        "if all_in_range:\n",
        "    print(\" - All images have pixel values ranging from 0 to 255\")\n",
        "else:\n",
        "    print(\" - Not all images have the same pixel values from 0 to 255\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjJ2cy9iQyOi"
      },
      "source": [
        "Aunque no todas las imágenes son del mismo tipo de datos, uint8, es bastante fácil garantizar que tendrán el mismo tipo de datos una vez que carguemos imágenes en conjuntos de datos. Sin embargo, confirmamos que todas las imágenes tienen valores de píxeles que van de 0 a 255, lo cual es una gran noticia.\n",
        "\n",
        "Antes de pasar al paso de preprocesamiento, tracemos algunas imágenes de cada clase para ver cómo se ven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:08.99982Z",
          "iopub.status.busy": "2023-10-15T13:24:08.999206Z",
          "iopub.status.idle": "2023-10-15T13:24:09.00824Z",
          "shell.execute_reply": "2023-10-15T13:24:09.007345Z",
          "shell.execute_reply.started": "2023-10-15T13:24:08.99979Z"
        },
        "id": "b2ODSau1QyOi"
      },
      "outputs": [],
      "source": [
        "# Loading the directory for each class in the training dataset\n",
        "train_healthy_dir = train_dir + \"/\" + 'healthy'\n",
        "train_rust_dir = train_dir + \"/\" + 'rust'\n",
        "train_powdery_dir = train_dir + \"/\" + 'powdery'\n",
        "\n",
        "# Selecting 2 random pictures from each directory\n",
        "healthy_files = random.sample(os.listdir(train_healthy_dir), 2)\n",
        "rust_files = random.sample(os.listdir(train_rust_dir), 2)\n",
        "powdery_files = random.sample(os.listdir(train_powdery_dir), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOdX8idlb10O"
      },
      "outputs": [],
      "source": [
        "# Plot dos imágenes\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for i in (healthy_files):\n",
        "    img = mpimg.imread(train_healthy_dir + '/' + i)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:12.753932Z",
          "iopub.status.busy": "2023-10-15T13:24:12.753546Z",
          "iopub.status.idle": "2023-10-15T13:24:17.018945Z",
          "shell.execute_reply": "2023-10-15T13:24:17.017981Z",
          "shell.execute_reply.started": "2023-10-15T13:24:12.753893Z"
        },
        "id": "1CL_s_cwQyOi"
      },
      "outputs": [],
      "source": [
        "# Plot dos imágenes\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for i in (rust_files):\n",
        "    img = mpimg.imread(train_rust_dir + '/' + i)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:17.025229Z",
          "iopub.status.busy": "2023-10-15T13:24:17.024284Z",
          "iopub.status.idle": "2023-10-15T13:24:21.563379Z",
          "shell.execute_reply": "2023-10-15T13:24:21.562443Z",
          "shell.execute_reply.started": "2023-10-15T13:24:17.025195Z"
        },
        "id": "KaX5x5d7QyOi"
      },
      "outputs": [],
      "source": [
        "# Plot dos imágenes\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for i in (powdery_files):\n",
        "    img = mpimg.imread(train_powdery_dir + '/' + i)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiyvuG1_QyOj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCBjwiedQyOj"
      },
      "source": [
        "Para quienes están familiarizados con los datos tabulares, el preprocesamiento es probablemente uno de los pasos más desalentadores al tratar con redes neuronales y datos no estructurados.\n",
        "\n",
        "Esta tarea puede ser bastante sencilla utilizando image_dataset_from_directory de TensorFlow, que carga imágenes de los directorios como un conjunto de datos de TensorFlow. Este conjunto de datos resultante se puede manipular para realizar lotes, barajar, aumentar y varios otros pasos de preprocesamiento.\n",
        "\n",
        "Le sugiero que consulte este enlace para obtener más información sobre la función `image_dataset_from_directory`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:21.565518Z",
          "iopub.status.busy": "2023-10-15T13:24:21.564633Z",
          "iopub.status.idle": "2023-10-15T13:24:22.352412Z",
          "shell.execute_reply": "2023-10-15T13:24:22.351549Z",
          "shell.execute_reply.started": "2023-10-15T13:24:21.565488Z"
        },
        "id": "jeiWbrDtQyOj"
      },
      "outputs": [],
      "source": [
        "# Creating a Dataset for the Training data\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,  # Directory where the Training images are located\n",
        "    labels = 'inferred', # Classes will be inferred according to the structure of the directory\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['healthy', 'powdery', 'rust'],\n",
        "    batch_size = 128,    # Number of processed samples before updating the model's weights\n",
        "    image_size = (256, 256), # Defining a fixed dimension for all images\n",
        "    shuffle = True,  # Shuffling data\n",
        "    seed = seed,  # Random seed for shuffling and transformations\n",
        "    validation_split = 0, # We don't need to create a validation set from the training set\n",
        "    crop_to_aspect_ratio = True # Resize images without aspect ratio distortion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:22.354677Z",
          "iopub.status.busy": "2023-10-15T13:24:22.353677Z",
          "iopub.status.idle": "2023-10-15T13:24:22.46944Z",
          "shell.execute_reply": "2023-10-15T13:24:22.468488Z",
          "shell.execute_reply.started": "2023-10-15T13:24:22.354647Z"
        },
        "id": "sDT3MesoQyOj"
      },
      "outputs": [],
      "source": [
        "# Creating a dataset for the Test data\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['healthy', 'powdery', 'rust'],\n",
        "    batch_size = 128,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:22.471718Z",
          "iopub.status.busy": "2023-10-15T13:24:22.470863Z",
          "iopub.status.idle": "2023-10-15T13:24:22.557211Z",
          "shell.execute_reply": "2023-10-15T13:24:22.556206Z",
          "shell.execute_reply.started": "2023-10-15T13:24:22.471679Z"
        },
        "id": "wLAgZqkuQyOj"
      },
      "outputs": [],
      "source": [
        "# Creating a dataset for the Validation data\n",
        "validation = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    class_names = ['healthy', 'powdery', 'rust'],\n",
        "    batch_size = 128,\n",
        "    image_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    validation_split = 0,\n",
        "    crop_to_aspect_ratio = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aupy8XJfQyOk"
      },
      "source": [
        "Hemos capturado con éxito todos los archivos dentro de cada conjunto para cada una de las tres clases. También podemos imprimir estos conjuntos de datos para comprender mejor su estructura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:22.559535Z",
          "iopub.status.busy": "2023-10-15T13:24:22.55866Z",
          "iopub.status.idle": "2023-10-15T13:24:22.564524Z",
          "shell.execute_reply": "2023-10-15T13:24:22.56373Z",
          "shell.execute_reply.started": "2023-10-15T13:24:22.559505Z"
        },
        "id": "bKskmJKGQyOk"
      },
      "outputs": [],
      "source": [
        "print('\\nTraining Dataset:', train)\n",
        "print('\\nTesting Dataset:', test)\n",
        "print('\\nValidation Dataset:', validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiUd3PknQyOk"
      },
      "source": [
        "Exploremos un poco más a fondo lo que significa toda la información anterior.\n",
        "\n",
        "• `BatchDataset`: Indica que el conjunto de datos devuelve datos en lotes.\n",
        "\n",
        "• `element_spec`: describe la estructura de los elementos del conjunto de datos.\n",
        "\n",
        "• `TensorSpec`(shape=(Ninguno, 256, 256, 3), dtype=tf.float32, nombre = Ninguno): esto representa las características, en este caso las imágenes, en el conjunto de datos. Ninguno representa el tamaño del lote, que aquí es Ninguno porque puede variar dependiendo de cuántas muestras tengamos en el último lote; 256, 256 representa el alto y ancho de las imágenes; 3 es el número de canales en las imágenes, lo que indica que son imágenes RGB. Por último, dtype=tf.float32 nos dice que el tipo de datos de los píxeles de la imagen es un punto flotante de 32 bits.\n",
        "\n",
        "• `TensorSpec`(shape=(None, 3), dtype=tf.float32, name=None): esto representa las etiquetas/objetivos de nuestro conjunto de datos. Aquí Ninguno se refiere al tamaño del lote; 3 se refiere al número de etiquetas en el conjunto de datos; mientras que dtype=tf.float32 también es un punto flotante de 32 bits.\n",
        "\n",
        "Al utilizar la función image_dataset_from_directory, hemos podido preprocesar automáticamente algunos aspectos de los datos. Por ejemplo, todas las imágenes ahora son del mismo tipo de datos, `tf.float32`. Al establecer image_size = (256, 256), nos hemos asegurado de que todas las imágenes tengan las mismas dimensiones, `256 x 256`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEkrffr8QyOk"
      },
      "source": [
        "Otro paso importante para el preprocesamiento es garantizar que los valores de píxeles de nuestras imágenes estén dentro de un rango de 0 a 1. El método image_dataset_from_directory ya realizó algunas transformaciones, pero los valores de píxeles todavía están en el rango de 0 a 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:22.56665Z",
          "iopub.status.busy": "2023-10-15T13:24:22.565776Z",
          "iopub.status.idle": "2023-10-15T13:24:27.139442Z",
          "shell.execute_reply": "2023-10-15T13:24:27.137193Z",
          "shell.execute_reply.started": "2023-10-15T13:24:22.566623Z"
        },
        "id": "JGgT0oLAQyOk"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in validation:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN4HiWEYQyOl"
      },
      "source": [
        "Para llevar los valores de píxeles al rango de 0 a 1, podemos usar fácilmente una de las capas de preprocesamiento de Keras, `tf.keras.layers.Rescaling`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:27.140974Z",
          "iopub.status.busy": "2023-10-15T13:24:27.140607Z",
          "iopub.status.idle": "2023-10-15T13:24:27.16725Z",
          "shell.execute_reply": "2023-10-15T13:24:27.162803Z",
          "shell.execute_reply.started": "2023-10-15T13:24:27.140937Z"
        },
        "id": "5_KjZ3olQyOl"
      },
      "outputs": [],
      "source": [
        "scaler = Rescaling(1./255) # Defining scaler values between 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:27.170675Z",
          "iopub.status.busy": "2023-10-15T13:24:27.169867Z",
          "iopub.status.idle": "2023-10-15T13:24:27.268104Z",
          "shell.execute_reply": "2023-10-15T13:24:27.267204Z",
          "shell.execute_reply.started": "2023-10-15T13:24:27.170645Z"
        },
        "id": "o95GaQbUQyOl"
      },
      "outputs": [],
      "source": [
        "# Rescaling datasets\n",
        "train = train.map(lambda x, y: (scaler(x), y))\n",
        "test = test.map(lambda x, y: (scaler(x), y))\n",
        "validation = validation.map(lambda x, y: (scaler(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMWLwkS3QyOl"
      },
      "source": [
        "Ahora podemos visualizar una vez más los valores mínimo y máximo de píxeles en el conjunto de validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:27.27003Z",
          "iopub.status.busy": "2023-10-15T13:24:27.269524Z",
          "iopub.status.idle": "2023-10-15T13:24:30.646058Z",
          "shell.execute_reply": "2023-10-15T13:24:30.645201Z",
          "shell.execute_reply.started": "2023-10-15T13:24:27.270001Z"
        },
        "id": "ih6YqGovQyOl"
      },
      "outputs": [],
      "source": [
        "# Checking minimum and maximum pixel values in the Validation dataset\n",
        "min_value = float('inf')\n",
        "max_value = -float('inf')\n",
        "\n",
        "for img, label in validation:\n",
        "    batch_min = tf.reduce_min(img)\n",
        "    batch_max = tf.reduce_max(img)\n",
        "\n",
        "    min_value = min(min_value, batch_min.numpy())\n",
        "    max_value = max(max_value, batch_max.numpy())\n",
        "\n",
        "print('\\nMinimum pixel value in the Validation dataset', min_value)\n",
        "print('\\nMaximum pixel value in the Validation dataset', max_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNiOHiq0QyOl"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO8coM3-QyOl"
      },
      "source": [
        "Cuando se trabaja con datos de imágenes, suele ser una buena práctica introducir artificialmente cierta diversidad en la muestra aplicando transformaciones aleatorias a las imágenes utilizadas en el entrenamiento. Esto es bueno porque ayuda a exponer el modelo a una variedad más amplia de imágenes y evita el sobreajuste.\n",
        "\n",
        "Keras tiene alrededor de siete capas diferentes para aumentar los datos de imágenes. Estos son:\n",
        "\n",
        "• `tf.keras.layers.RandomCrop`: esta capa elige aleatoriamente una ubicación para recortar imágenes hasta un tamaño objetivo.\n",
        "\n",
        "• `tf.keras.layers.RandomFlip`: esta capa voltea imágenes aleatoriamente horizontal o verticalmente según el atributo de modo.\n",
        "\n",
        "• `tf.keras.layers.RandomTranslation`: esta capa aplica traducciones aleatoriamente a cada imagen durante el entrenamiento de acuerdo con el atributo fill_mode.\n",
        "\n",
        "• `tf.keras.layers.RandomBrightness`: esta capa aumenta/reduce aleatoriamente el brillo de las imágenes RGB de entrada.\n",
        "\n",
        "• `tf.keras.layers.RandomRotation: esta capa rota aleatoriamente las imágenes durante el entrenamiento y también llena los espacios vacíos según el atributo fill_mode.\n",
        "\n",
        "• `tf.keras.layers.RandomZoom`: esta capa acerca o aleja aleatoriamente cada eje de cada imagen de forma independiente durante el entrenamiento.\n",
        "\n",
        "• `tf.keras.layers.RandomContrast`: esta capa ajusta aleatoriamente el contraste mediante un factor aleatorio durante el entrenamiento dentro o fuera de cada eje de cada imagen de forma independiente durante el entrenamiento.\n",
        "\n",
        "Para esta tarea, aplicaremos `RandomRotation`, `RandomContrast` y `RandomBrightness` a nuestras imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:30.648101Z",
          "iopub.status.busy": "2023-10-15T13:24:30.64757Z",
          "iopub.status.idle": "2023-10-15T13:24:30.666045Z",
          "shell.execute_reply": "2023-10-15T13:24:30.665177Z",
          "shell.execute_reply.started": "2023-10-15T13:24:30.64807Z"
        },
        "id": "07kN2XUEQyOm"
      },
      "outputs": [],
      "source": [
        "# Creating data augmentation pipeline\n",
        "augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(\n",
        "        factor = (-.25, .3),\n",
        "        fill_mode = 'reflect',\n",
        "        interpolation = 'bilinear',\n",
        "        seed = seed),\n",
        "\n",
        "\n",
        "        tf.keras.layers.RandomBrightness(\n",
        "        factor = (-.45, .45),\n",
        "        value_range = (0.0, 1.0),\n",
        "        seed = seed),\n",
        "\n",
        "        tf.keras.layers.RandomContrast(\n",
        "        factor = (.5),\n",
        "        seed = seed)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDmieJD8QyOm"
      },
      "source": [
        "También podemos usar input_shape como ejemplo para construir la tubería de arriba y trazarla a continuación para ilustrar su apariencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:30.668054Z",
          "iopub.status.busy": "2023-10-15T13:24:30.66754Z",
          "iopub.status.idle": "2023-10-15T13:24:30.98597Z",
          "shell.execute_reply": "2023-10-15T13:24:30.985103Z",
          "shell.execute_reply.started": "2023-10-15T13:24:30.668026Z"
        },
        "id": "I1PVJEIKQyOm"
      },
      "outputs": [],
      "source": [
        "augmentation.build((None, 256, 256, 3)) # Building model\n",
        "# Plotting model\n",
        "tf.keras.utils.plot_model(augmentation,\n",
        "                          show_shapes = True,\n",
        "                          show_layer_names = True,\n",
        "                          expand_nested = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWwq3CV5QyOm"
      },
      "source": [
        "Vamos a conectar este canal de aumento de datos a nuestra red neuronal convolucional. Es importante recordar que la canalización de aumento de datos está inactiva durante las pruebas y las muestras de entrada solo se aumentarán durante `fit()`, no cuando se llama a `predict()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0oVi8V9QyOm"
      },
      "source": [
        "## Building the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F82GsON1QyOm"
      },
      "source": [
        "Para construir la red neuronal convolucional con Keras, usaremos la clase Sequential. Esta clase nos permite construir una pila lineal de capas, lo cual es esencial para la creación de redes neuronales.\n",
        "\n",
        "Además de las capas convolucional, de agrupación y totalmente conectada, que hemos explorado anteriormente, también voy a agregar las siguientes capas a la red:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDDGuIqmQyOm"
      },
      "source": [
        "• `BatchNormalization`: Esta capa aplica una transformación que mantiene la salida media cerca de `0` y la desviación estándar cerca de `1`. Normaliza sus entradas y es importante para ayudar a la convergencia y la generalización.\n",
        "\n",
        "• `Dropout`: esta capa establece aleatoriamente una fracción de las unidades de entrada en $0$ durante el entrenamiento, lo que ayuda a evitar el sobreajuste.\n",
        "\n",
        "• `Flatten`: esta capa transforma un tensor multidimensional en un tensor unidimensional. Se utiliza al realizar la transición del segmento de aprendizaje de funciones (capas convolucionales y de agrupación) a las capas completamente conectadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:30.988159Z",
          "iopub.status.busy": "2023-10-15T13:24:30.987118Z",
          "iopub.status.idle": "2023-10-15T13:24:31.037395Z",
          "shell.execute_reply": "2023-10-15T13:24:31.036571Z",
          "shell.execute_reply.started": "2023-10-15T13:24:30.988098Z"
        },
        "id": "ENZ9tjr0QyOn"
      },
      "outputs": [],
      "source": [
        "# Initiating model on GPU\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(augmentation) # Adding data augmentation pipeline to the model\n",
        "\n",
        "    # Feature Learning Layers\n",
        "    model.add(Conv2D(32,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same',    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    input_shape = (256,256,3) # Input image shape\n",
        "                    ))\n",
        "    model.add(Activation('relu'))#TODO Activation function\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same')) #TODO\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # TODO Agregar 4 bloques convolucionales adicionales\n",
        "\n",
        "    model.add(Conv2D(64,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same'    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(128,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same'    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(256,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same'    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512,                  # Number of filters/Kernels\n",
        "                     (3,3),               # Size of kernels (3x3 matrix)\n",
        "                     strides = 1,         # Step size for sliding the kernel across the input (1 pixel at a time).\n",
        "                     padding = 'same'    # 'Same' ensures that the output feature map has the same dimensions as the input by padding zeros around the input.\n",
        "                    ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2), padding = 'same'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Flattening tensors\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully-Connected Layers\n",
        "    model.add(Dense(2048))\n",
        "    model.add(Activation('relu')) #TODO\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(3, activation = 'softmax')) #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:31.038943Z",
          "iopub.status.busy": "2023-10-15T13:24:31.038656Z",
          "iopub.status.idle": "2023-10-15T13:24:31.060466Z",
          "shell.execute_reply": "2023-10-15T13:24:31.05964Z",
          "shell.execute_reply.started": "2023-10-15T13:24:31.038922Z"
        },
        "id": "ko1M4dWHQyOn"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(0.0001), # 1e-4\n",
        "              loss = 'categorical_crossentropy', #TODO Ideal for multiclass tasks\n",
        "              metrics = ['accuracy']) # Evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCfgVZ5PQyOn"
      },
      "source": [
        "Después de compilar el modelo, definiras una parada temprana y un punto de control del modelo.\n",
        "\n",
        "La parada temprana tiene el propósito de interrumpir el proceso de capacitación cuando una determinada métrica deja de mejorar durante un período de tiempo. En este caso, voy a configurar el método EarlyStopping para monitorear la precisión en el conjunto de pruebas y detener el proceso de entrenamiento si no logramos ninguna mejora después de 5 épocas.\n",
        "\n",
        "Model Checkpoint garantizará que solo se guarden los mejores pesos y también definiremos los mejores pesos de acuerdo con la precisión del modelo en el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:31.062184Z",
          "iopub.status.busy": "2023-10-15T13:24:31.061862Z",
          "iopub.status.idle": "2023-10-15T13:24:31.066912Z",
          "shell.execute_reply": "2023-10-15T13:24:31.06571Z",
          "shell.execute_reply.started": "2023-10-15T13:24:31.062148Z"
        },
        "id": "IxPqTH57QyOn"
      },
      "outputs": [],
      "source": [
        "# Defining an Early Stopping and Model Checkpoints\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              patience = 5, mode = 'max',\n",
        "                              restore_best_weights = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5',\n",
        "                            monitor = 'val_accuracy',\n",
        "                            save_best_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.__dict__"
      ],
      "metadata": {
        "id": "keeO83ZYW3b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:24:31.068709Z",
          "iopub.status.busy": "2023-10-15T13:24:31.067984Z",
          "iopub.status.idle": "2023-10-15T13:56:17.400315Z",
          "shell.execute_reply": "2023-10-15T13:56:17.399352Z",
          "shell.execute_reply.started": "2023-10-15T13:24:31.068679Z"
        },
        "id": "FR9y--LPQyOn"
      },
      "outputs": [],
      "source": [
        "# Training and Testing Model\n",
        "try:\n",
        "    path = '/content/drive/MyDrive/Colab_Notebooks/06_Deep_learning/5.archivos'\n",
        "    csv_logger = CSVLogger(path+'history_log.csv', append=True, separator=';')\n",
        "\n",
        "    history = model.fit(\n",
        "        train, epochs = 10,\n",
        "        validation_data = test,\n",
        "        callbacks = [early_stopping, checkpoint, csv_logger])\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNKep6swQyOn"
      },
      "source": [
        "La precisión más alta para el conjunto de pruebas se alcanzó en la época 22 con 0,9600, o 96 %, y no mejoró después de eso.\n",
        "\n",
        "Con el objeto histórico, podemos trazar dos gráficos de líneas que muestren tanto la función de pérdida como la precisión para ambos conjuntos a lo largo de épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T14:01:38.413405Z",
          "iopub.status.busy": "2023-10-15T14:01:38.413024Z",
          "iopub.status.idle": "2023-10-15T14:01:38.456542Z",
          "shell.execute_reply": "2023-10-15T14:01:38.455701Z",
          "shell.execute_reply.started": "2023-10-15T14:01:38.413377Z"
        },
        "id": "MOrUFEarQyOo"
      },
      "outputs": [],
      "source": [
        "# Creating subplot\n",
        "fig = make_subplots(rows=1,\n",
        "                    cols=2,\n",
        "                    subplot_titles=['<b>Loss Over Epochs</b>', '<b>Accuracy Over Epochs</b>'],\n",
        "                    horizontal_spacing=0.2)\n",
        "\n",
        "# Loss over epochs\n",
        "train_loss = go.Scatter(x=list(range(len(history.history['loss']))),\n",
        "                        y=history.history['loss'],\n",
        "                        mode='lines',\n",
        "                        line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                        name='Training',\n",
        "                        showlegend = False)\n",
        "\n",
        "val_loss = go.Scatter(x=list(range(len(history.history['val_loss']))),\n",
        "                      y=history.history['val_loss'],\n",
        "                      mode='lines',\n",
        "                      line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                      name='Test',\n",
        "                      showlegend = False)\n",
        "\n",
        "\n",
        "fig.add_trace(train_loss, row=1, col=1)\n",
        "fig.add_trace(val_loss, row=1, col=1)\n",
        "\n",
        "# Accuray over epochs\n",
        "train_acc = go.Scatter(x=list(range(len(history.history['accuracy']))),\n",
        "                       y=history.history['accuracy'],\n",
        "                       mode='lines',\n",
        "                       line=dict(color='rgba(0, 67, 162, .75)', width=4.75),\n",
        "                       name='Training',\n",
        "                       showlegend = True)\n",
        "\n",
        "val_acc = go.Scatter(x=list(range(len(history.history['val_accuracy']))),\n",
        "                     y=history.history['val_accuracy'],\n",
        "                     mode='lines',\n",
        "                     line=dict(color='rgba(255, 132, 0, .75)', width=4.75),\n",
        "                     name='Test',\n",
        "                     showlegend = True)\n",
        "\n",
        "\n",
        "fig.add_trace(train_acc, row=1, col=2)\n",
        "fig.add_trace(val_acc, row=1, col=2)\n",
        "\n",
        "# Updating layout\n",
        "fig.update_layout(\n",
        "    title={'text': '<b>Loss and Accuracy Over Epochs</b>', 'x': 0.025, 'xanchor': 'left'},\n",
        "    margin=dict(t=100),\n",
        "    plot_bgcolor=bg_color,paper_bgcolor=paper_color,\n",
        "    height=500, width=1000,\n",
        "    showlegend= True\n",
        ")\n",
        "\n",
        "fig.update_yaxes(title_text = 'Loss', row = 1, col = 1)\n",
        "fig.update_yaxes(title_text = 'Accuracy', row = 1, col = 2)\n",
        "\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 1)\n",
        "fig.update_xaxes(title_text = 'Epoch', row = 1, col = 2)\n",
        "\n",
        "# Showing figure\n",
        "#fig.show()  #No renderiza en Colab\n",
        "fig.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKyHT29mQyOo"
      },
      "source": [
        "Es posible ver que la pérdida del conjunto de entrenamiento disminuye continuamente a lo largo de las épocas, mientras que su precisión aumenta. Esto sucede porque, en cada época, el modelo comienza a ser cada vez más consciente de los patrones y particularidades del conjunto de entrenamiento.\n",
        "\n",
        "Sin embargo, para el conjunto de prueba, este proceso es un poco más lento. En general, la pérdida más baja para el conjunto de prueba ocurrió en la época 14 con 0,5319, mientras que la precisión alcanzó su punto máximo en la época 22, con 0,9600.\n",
        "\n",
        "Ahora que nuestro modelo está construido, entrenado y probado, también podemos trazar su arquitectura, así como resumirlo para comprenderlo mejor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:31.348694Z",
          "iopub.status.busy": "2023-10-15T13:56:31.347977Z",
          "iopub.status.idle": "2023-10-15T13:56:31.564662Z",
          "shell.execute_reply": "2023-10-15T13:56:31.56373Z",
          "shell.execute_reply.started": "2023-10-15T13:56:31.348662Z"
        },
        "id": "oLaTM5gMQyOo"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model) #TODO Plotting model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WpGWeyWQyOo"
      },
      "source": [
        "En la imagen se puede visualizar el proceso secuencial de la Red Neural Convolucional. Primero tenemos una capa convolucional 2D, con función de activación ReLU, seguida de una capa BatchNormalization y luego una capa 2D MaxPooling. Finalmente, tenemos una capa de abandono para evitar el sobreajuste. Este mismo patrón se repite varias veces hasta llegar a Aplanar capa, que conecta la salida del proceso de aprendizaje de características con las capas densas para la tarea de clasificación final.\n",
        "\n",
        "Usando `model.summary()`, podemos extraer información adicional sobre la red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:31.566589Z",
          "iopub.status.busy": "2023-10-15T13:56:31.566007Z",
          "iopub.status.idle": "2023-10-15T13:56:31.629284Z",
          "shell.execute_reply": "2023-10-15T13:56:31.628643Z",
          "shell.execute_reply.started": "2023-10-15T13:56:31.566561Z"
        },
        "id": "xequ15gYQyOo"
      },
      "outputs": [],
      "source": [
        " # TODO Printing model summary\n",
        " model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJxROrqxQyOp"
      },
      "source": [
        "## Validating Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3iyBkweQyOp"
      },
      "source": [
        "Después de finalizar la fase de capacitación y prueba, podemos continuar y validar nuestro modelo en el conjunto de validación. Para cargar los mejores pesos conseguidos durante el entrenamiento, simplemente utilizamos el método load_weights. Estos pesos se guardarán con el mismo nombre que les dimos durante la configuración de ModelCheckpoint, cuando configuramos ModelCheckpoint('best_model.h5')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:31.630369Z",
          "iopub.status.busy": "2023-10-15T13:56:31.63007Z",
          "iopub.status.idle": "2023-10-15T13:56:32.22102Z",
          "shell.execute_reply": "2023-10-15T13:56:32.220095Z",
          "shell.execute_reply.started": "2023-10-15T13:56:31.630343Z"
        },
        "id": "_a0A_wn-QyOp"
      },
      "outputs": [],
      "source": [
        "# Loading best weights\n",
        "model.load_weights('best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:32.223174Z",
          "iopub.status.busy": "2023-10-15T13:56:32.222514Z",
          "iopub.status.idle": "2023-10-15T13:56:38.84721Z",
          "shell.execute_reply": "2023-10-15T13:56:38.846175Z",
          "shell.execute_reply.started": "2023-10-15T13:56:32.223141Z"
        },
        "id": "SEQIbG5UQyOp"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(validation)  # Running model on the validation dataset\n",
        "val_loss, val_acc = model.evaluate(validation) # Obtaining Loss and Accuracy on the val dataset\n",
        "\n",
        "print('\\nValidation Loss: ', val_loss)\n",
        "print('\\nValidation Accuracy: ', np.round(val_acc * 100), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:38.848951Z",
          "iopub.status.busy": "2023-10-15T13:56:38.848616Z",
          "iopub.status.idle": "2023-10-15T13:56:39.272735Z",
          "shell.execute_reply": "2023-10-15T13:56:39.271939Z",
          "shell.execute_reply.started": "2023-10-15T13:56:38.848921Z"
        },
        "id": "yNlf5yRnQyOq"
      },
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Powdery directory\n",
        "image_path = os.path.join(val_dir,'powdery/9b6a318cc5721d73.jpg') #TODO complete path\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Powdery Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:39.274985Z",
          "iopub.status.busy": "2023-10-15T13:56:39.274386Z",
          "iopub.status.idle": "2023-10-15T13:56:39.733431Z",
          "shell.execute_reply": "2023-10-15T13:56:39.732476Z",
          "shell.execute_reply.started": "2023-10-15T13:56:39.274952Z"
        },
        "id": "H-8BMrHsQyOq"
      },
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['healthy', 'powdery', 'rust'] #TODO labels\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:39.735632Z",
          "iopub.status.busy": "2023-10-15T13:56:39.734629Z",
          "iopub.status.idle": "2023-10-15T13:56:40.101732Z",
          "shell.execute_reply": "2023-10-15T13:56:40.100984Z",
          "shell.execute_reply.started": "2023-10-15T13:56:39.735598Z"
        },
        "id": "1-J9RXAQQyOq"
      },
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Rust directory\n",
        "image_path = os.path.join(val_dir,'rust/8152cfbd5a28b5d2.jpg') #TODO complete path\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Rust Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:40.103557Z",
          "iopub.status.busy": "2023-10-15T13:56:40.102798Z",
          "iopub.status.idle": "2023-10-15T13:56:40.32906Z",
          "shell.execute_reply": "2023-10-15T13:56:40.328169Z",
          "shell.execute_reply.started": "2023-10-15T13:56:40.103525Z"
        },
        "id": "_Av_VcwqQyOq"
      },
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['healthy', 'powdery', 'rust'] #TODO labels\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T14:03:31.838421Z",
          "iopub.status.busy": "2023-10-15T14:03:31.837983Z",
          "iopub.status.idle": "2023-10-15T14:03:32.47319Z",
          "shell.execute_reply": "2023-10-15T14:03:32.472175Z",
          "shell.execute_reply.started": "2023-10-15T14:03:31.838389Z"
        },
        "id": "tu59XV3OQyOr"
      },
      "outputs": [],
      "source": [
        "# Loading an image from the Validation/ Healthy directory\n",
        "image_path = os.path.join(val_dir,'healthy/9c99786a63786571.jpg')  #TODO complete path\n",
        "original_image = Image.open(image_path)\n",
        "og_width, og_height = original_image.size\n",
        "\n",
        "# Resizing image for optimal performance\n",
        "new_width = int(og_width * .20) # 20% of the original size\n",
        "new_height = int(og_height * .20) # 20% of the original size\n",
        "\n",
        "resized_img = original_image.resize((new_width, new_height))\n",
        "print('Picture of a Healthy Plant: \\n')\n",
        "resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2023-10-15T14:03:37.686834Z",
          "iopub.status.busy": "2023-10-15T14:03:37.686517Z",
          "iopub.status.idle": "2023-10-15T14:03:37.897182Z",
          "shell.execute_reply": "2023-10-15T14:03:37.896222Z",
          "shell.execute_reply.started": "2023-10-15T14:03:37.686809Z"
        },
        "id": "sTkXlNnfQyOs"
      },
      "outputs": [],
      "source": [
        "# Manually preprocessing image\n",
        "preprocessed_image = original_image.resize((256, 256))\n",
        "preprocessed_image = np.array(preprocessed_image) / 255.0\n",
        "\n",
        "preds = model.predict(np.expand_dims(preprocessed_image, axis = 0))\n",
        "labels = ['healthy', 'powdery', 'rust'] #TODO labels\n",
        "\n",
        "preds_class = np.argmax(preds)\n",
        "preds_label = labels[preds_class]\n",
        "\n",
        "print(f'\\nPredicted Class: {preds_label}')\n",
        "print(f'\\nConfidence Score: {preds[0][preds_class]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "jkJGJdZbobXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-15T13:56:40.931608Z",
          "iopub.status.busy": "2023-10-15T13:56:40.931288Z",
          "iopub.status.idle": "2023-10-15T13:56:42.478677Z",
          "shell.execute_reply": "2023-10-15T13:56:42.477715Z",
          "shell.execute_reply.started": "2023-10-15T13:56:40.931578Z"
        },
        "id": "MynfqRGoQyOt"
      },
      "outputs": [],
      "source": [
        "model.save(os.path.join(base_path,'plant_disease_classifier.h5')) # Saving model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}